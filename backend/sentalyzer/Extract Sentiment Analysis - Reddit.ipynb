{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import download\n",
    "download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client['reddit-data']\n",
    "col_sub = db['submissions']\n",
    "submissions = pd.DataFrame(col_sub.find())\n",
    "col_com = db['comments']\n",
    "comments = pd.DataFrame(col_com.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_data(ticker, itemtype):\n",
    "    \n",
    "    \n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient()\n",
    "    \n",
    "    db = client['reddit-data'] \n",
    "    \n",
    "    \n",
    "    if itemtype == 'comments':\n",
    "        collection = db['comments']\n",
    "        \n",
    "    elif itemtype == 'submissions':\n",
    "        collection = db['submissions']\n",
    "        \n",
    "    #df = pd.DataFrame(collection.find())    \n",
    "    df = pd.read_csv(f'{itemtype}.csv',low_memory=False)\n",
    "        \n",
    "    columns = {'comments': 'body', 'submissions': 'selftext'}\n",
    "    \n",
    "    column = columns[itemtype]    \n",
    "    \n",
    "    df[column] = df[column].apply(lambda x: str(x).lower())\n",
    "    \n",
    "    df = pd.concat([df[df[column].str.contains(ticker.lower())], df[df[column].str.contains(TICKERS[ticker].lower())]],ignore_index=True)\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    additional  = ['rt','rts','retweet'] #we'll store additional stopwords here\n",
    "    swords = set().union(stopwords.words('english'),additional) #big list containing all the stopwords + our additional ones\n",
    "    df.drop_duplicates(subset=columns[itemtype],inplace=True)\n",
    "    \n",
    "    import nltk.sentiment.vader as vd\n",
    "    \n",
    "    sia = vd.SentimentIntensityAnalyzer()\n",
    "    df.dropna(subset=[column],inplace=True)\n",
    "    \n",
    "    df['processed_text'] = df[column].str.lower()\\\n",
    "          .str.replace('(@[a-z0-9]+)\\w+',' ')\\\n",
    "          .str.replace('(http\\S+)', ' ')\\\n",
    "          .str.replace('([^0-9a-z \\t])',' ')\\\n",
    "          .str.replace(' +',' ')\\\n",
    "          .apply(lambda x: [i for i in x.split() if not i in swords])\n",
    "    \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    df['sentiment_score'] = df['processed_text'].apply(lambda x: sum([ sia.polarity_scores(i)['compound'] for i in word_tokenize( ' '.join(x) )]) )\n",
    "    \n",
    "    df[['processed_text','sentiment_score']].sort_values(by='sentiment_score')\n",
    "    \n",
    "    sent_clasification = pd.cut(df['sentiment_score'],\\\n",
    "          [-3,-1.2, 0, 1.2 , 3],\\\n",
    "          right=True,\\\n",
    "          include_lowest=True,\\\n",
    "          labels=['strongly negative', 'negative', 'positive', 'strongly positive'])\n",
    "    \n",
    "    return dict(sent_clasification.value_counts())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets import TICKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_aggregates(ticker):\n",
    "    com_results = get_sentiment_data('MMM', 'comments' )\n",
    "    sub_results = get_sentiment_data('MMM', 'submissions' )\n",
    "    \n",
    "    labels=['strongly negative', 'negative', 'positive', 'strongly positive']\n",
    "    aggregation = {}\n",
    "    \n",
    "    for key in labels:\n",
    "        try:\n",
    "            aggregation[key] = com_results[key] + sub_results[key]\n",
    "        except e:\n",
    "            print(e)\n",
    "\n",
    "    return aggregation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
